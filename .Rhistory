write.xlsx(df_cs, "data_variables_roger.xlsx", row.names = FALSE)
library(readxl)
reshaped_poi_locations <- read_excel("reshaped_poi_locations.xlsx")
View(reshaped_poi_locations)
df_model<-reshaped_poi_locations[, c(1:750)]
View(df_model)
df_model<-reshaped_poi_locations[, c(1:725)]
View(df_model)
df_model<-reshaped_poi_locations[, c(1:714, 716, 726:790)]
View(df_model)
df_model<-reshaped_poi_locations[, c(1:715, 717, 726:790)]
df_model<-reshaped_poi_locations[, c(1:714, 717, 732:790)]
View(reshaped_poi_locations)
library(randomForest)
library(xgboost)
library(rstanarm)
library(nnet)
library(readxl)
library(e1071)
library(gbm)
df_model <- read_excel("reshaped_poi_locations.xlsx")
# Splitting the data into training and testing sets balanced by Rating variable
set.seed(123)  # For reproducibility
train_indices <- createDataPartition(df_model$Rating, p = 0.7, list = FALSE)
createDataPartitio
library(caret)
df_model <- read_excel("reshaped_poi_locations.xlsx")
# Splitting the data into training and testing sets balanced by Rating variable
set.seed(123)  # For reproducibility
train_indices <- createDataPartition(df_model$Rating, p = 0.7, list = FALSE)
train_data <- df_model[train_indices, ]
test_data <- df_model[-train_indices, ]
# Random Forest
rf_model <- randomForest(formula = Rating ~ ., data = train_data)
rf_pred_train <- predict(rf_model, newdata = train_data)
rf_rmse_train <- sqrt(mean((rf_pred_train - train_data$Rating)^2))
rf_pred_test <- predict(rf_model, newdata = test_data)
rf_rmse_test <- sqrt(mean((rf_pred_test - test_data$Rating)^2))
# Assuming "Rating" is the column name you want to find the number of
column_name <- "Rating"
column_number <- which(names(df_model) == column_name)
print(column_number)
# XGBoost
xgb_model <- xgboost(data = as.matrix(train_data[, -column_number]), label = train_data$Rating, nrounds = 100)
xgb_pred_train <- predict(xgb_model, newdata = as.matrix(train_data[, -column_number]))
xgb_rmse_train <- sqrt(mean((xgb_pred_train - train_data$Rating)^2))
xgb_pred_test <- predict(xgb_model, newdata = as.matrix(test_data[, -column_number]))
xgb_rmse_test <- sqrt(mean((xgb_pred_test - test_data$Rating)^2))
# SVM
svm_model <- svm(Rating ~ ., data = train_data, kernel = "radial")
svm_pred_train <- predict(svm_model, newdata = train_data)
svm_rmse_train <- sqrt(mean((svm_pred_train - train_data$Rating)^2))
svm_pred_test <- predict(svm_model, newdata = test_data)
svm_rmse_test <- sqrt(mean((svm_pred_test - test_data$Rating)^2))
# GBM
gbm_model <- gbm(Rating ~ ., data = train_data, n.trees = 100, interaction.depth = 3, shrinkage = 0.1)
gbm_pred_train <- predict(gbm_model, newdata = train_data, n.trees = 100)
gbm_rmse_train <- sqrt(mean((gbm_pred_train - train_data$Rating)^2))
gbm_pred_test <- predict(gbm_model, newdata = test_data, n.trees = 100)
gbm_rmse_test <- sqrt(mean((gbm_pred_test - test_data$Rating)^2))
# Bayesian Regression
bayesian_model <- stan_glm(Rating ~ ., data = train_data, family = "gaussian")
bayesian_pred_train <- predict(bayesian_model, newdata = train_data)
bayesian_rmse_train <- sqrt(mean((bayesian_pred_train - train_data$Rating)^2))
bayesian_pred_test <- predict(bayesian_model, newdata = test_data)
# Bayesian Regression
bayesian_model <- stan_glm(Rating ~ ., data = train_data, family = "gaussian")
bayesian_pred_train <- predict(bayesian_model, newdata = train_data)
bayesian_rmse_train <- sqrt(mean((bayesian_pred_train - train_data$Rating)^2))
bayesian_pred_test <- predict(bayesian_model, newdata = test_data)
bayesian_rmse_test <- sqrt(mean((bayesian_pred_test - test_data$Rating)^2))
# Conventional Neural Network
nn_model <- nnet(Rating ~ ., data = train_data, size = 5, maxit = 100)
nn_pred_train <- predict(nn_model, newdata = train_data, type = "raw")
nn_rmse_train <- sqrt(mean((nn_pred_train - train_data$Rating)^2))
nn_pred_test <- predict(nn_model, newdata = test_data, type = "raw")
nn_rmse_test <- sqrt(mean((nn_pred_test - test_data$Rating)^2))
# Print RMSE for each model
print(paste("Random Forest Train RMSE:", rf_rmse_train))
print(paste("Random Forest Test RMSE:", rf_rmse_test))
print(paste("XGBoost Train RMSE:", xgb_rmse_train))
print(paste("XGBoost Test RMSE:", xgb_rmse_test))
print(paste("SVM Train RMSE:", svm_rmse_train))
print(paste("SVM Test RMSE:", svm_rmse_test))
print(paste("GBM Train RMSE:", gbm_rmse_train))
print(paste("GBM Test RMSE:", gbm_rmse_test))
print(paste("Bayesian Regression Train RMSE:", bayesian_rmse_train))
library(nnet)
# Conventional Neural Network
nn_model <- nnet(Rating ~ ., data = train_data, size = 5, maxit = 100)
# Conventional Neural Network
nn_model <- nnet(Rating ~ ., data = train_data, size = 500, maxit = 100)
# Conventional Neural Network
nn_model <- nnet(Rating ~ ., data = train_data, size = 391501, maxit = 100)
# Bayesian Regression
bayesian_model <- stan_glm(Rating ~ ., data = train_data, family = "gaussian")
# Identify constant variables
constant_vars <- sapply(train_data, function(x) length(unique(x)) == 1)
train_data <- train_data[, !constant_vars]
# Bayesian Regression
bayesian_model <- stan_glm(Rating ~ ., data = train_data, family = "gaussian")
library(glmnet)
library(readxl)
# Load the data from an Excel file
df_model <- read_excel("reshaped_poi_locations.xlsx")
# Splitting the data into training and testing sets balanced by Rating variable
set.seed(123)  # For reproducibility
train_indices <- createDataPartition(df_model$Rating, p = 0.7, list = FALSE)
train_data <- df_model[train_indices, ]
test_data <- df_model[-train_indices, ]
# Lasso Regression
x_train <- as.matrix(train_data[, -column_number])  # Exclude the Rating column
y_train <- train_data$Rating
lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "gaussian")
best_lambda <- lasso_model$lambda.min
lasso_pred_train <- predict(lasso_model, newx = x_train, s = best_lambda)
lasso_rmse_train <- sqrt(mean((lasso_pred_train - y_train)^2))
x_test <- as.matrix(test_data[, -1])  # Exclude the Rating column
y_test <- test_data$Rating
lasso_pred_test <- predict(lasso_model, newx = x_test, s = best_lambda)
lasso_rmse_test <- sqrt(mean((lasso_pred_test - y_test)^2))
# Print RMSE for Lasso Regression model
print(paste("Lasso Regression Train RMSE:", lasso_rmse_train))
print(paste("Lasso Regression Test RMSE:", lasso_rmse_test))
lasso_pred_test <- predict(lasso_model, newx = x_test, s = best_lambda)
library(glmnet)
library(readxl)
# Load the data from an Excel file
df_model <- read_excel("reshaped_poi_locations.xlsx")
# Splitting the data into training and testing sets balanced by Rating variable
set.seed(123)  # For reproducibility
train_indices <- createDataPartition(df_model$Rating, p = 0.7, list = FALSE)
train_data <- df_model[train_indices, ]
test_data <- df_model[-train_indices, ]
# Lasso Regression
x_train <- as.matrix(train_data[, -column_number])  # Exclude the Rating column
y_train <- train_data$Rating
lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "gaussian")
best_lambda <- lasso_model$lambda.min
lasso_pred_test <- predict(lasso_model, newx = x_test, s = best_lambda)
lasso_rmse_test <- sqrt(mean((lasso_pred_test - y_test)^2))
library(randomForest)
library(caret)
library(xgboost)
library(rstanarm)
library(nnet)
library(readxl)
library(e1071)
library(gbm)
df_model <- read_excel("reshaped_poi_locations.xlsx")
# Set up 10-fold cross-validation
num_folds <- 10
folds <- createFolds(df_model$Rating, k = num_folds, list = TRUE, returnTrain = TRUE)
# Initialize vectors to store RMSE values for each model
rf_rmse_train <- numeric(num_folds)
rf_rmse_test <- numeric(num_folds)
xgb_rmse_train <- numeric(num_folds)
xgb_rmse_test <- numeric(num_folds)
svm_rmse_train <- numeric(num_folds)
svm_rmse_test <- numeric(num_folds)
gbm_rmse_train <- numeric(num_folds)
gbm_rmse_test <- numeric(num_folds)
# Perform cross-validation
for (i in 1:num_folds) {
# Get training and testing data for the current fold
train_data <- df_model[folds[[i]], ]
test_data <- df_model[-folds[[i]], ]
# Random Forest
rf_model <- randomForest(formula = Rating ~ ., data = train_data)
rf_pred_train <- predict(rf_model, newdata = train_data)
rf_rmse_train[i] <- sqrt(mean((rf_pred_train - train_data$Rating)^2))
rf_pred_test <- predict(rf_model, newdata = test_data)
rf_rmse_test[i] <- sqrt(mean((rf_pred_test - test_data$Rating)^2))
# Assuming "Rating" is the column name you want to find the number of
column_name <- "Rating"
column_number <- which(names(df_model) == column_name)
# XGBoost
xgb_model <- xgboost(data = as.matrix(train_data[, -column_number]), label = train_data$Rating, nrounds = 100)
xgb_pred_train <- predict(xgb_model, newdata = as.matrix(train_data[, -column_number]))
xgb_rmse_train[i] <- sqrt(mean((xgb_pred_train - train_data$Rating)^2))
xgb_pred_test <- predict(xgb_model, newdata = as.matrix(test_data[, -column_number]))
xgb_rmse_test[i] <- sqrt(mean((xgb_pred_test - test_data$Rating)^2))
# SVM
svm_model <- svm(Rating ~ ., data = train_data, kernel = "radial")
svm_pred_train <- predict(svm_model, newdata = train_data)
svm_rmse_train[i] <- sqrt(mean((svm_pred_train - train_data$Rating)^2))
svm_pred_test <- predict(svm_model, newdata = test_data)
svm_rmse_test[i] <- sqrt(mean((svm_pred_test - test_data$Rating)^2))
# GBM
gbm_model <- gbm(Rating ~ ., data = train_data, n.trees = 100, interaction.depth = 3, shrinkage = 0.1)
gbm_pred_train <- predict(gbm_model, newdata = train_data, n.trees = 100)
gbm_rmse_train[i] <- sqrt(mean((gbm_pred_train - train_data$Rating)^2))
gbm_pred_test <- predict(gbm_model, newdata = test_data, n.trees = 100)
gbm_rmse_test[i] <- sqrt(mean((gbm_pred_test - test_data$Rating)^2))
}
# Compute the average RMSE across all folds
avg_rf_rmse_train <- mean(rf_rmse_train)
avg_rf_rmse_test <- mean(rf_rmse_test)
avg_xgb_rmse_train <- mean(xgb_rmse_train)
avg_xgb_rmse_test <- mean(xgb_rmse_test)
avg_svm_rmse_train <- mean(svm_rmse_train)
avg_svm_rmse_test <- mean(svm_rmse_test)
avg_gbm_rmse_train <- mean(gbm_rmse_train)
avg_gbm_rmse_test <- mean(gbm_rmse_test)
# Print average RMSE for each model
print(paste("Random Forest Train RMSE:", avg_rf_rmse_train))
print(paste("Random Forest Test RMSE:", avg_rf_rmse_test))
print(paste("XGBoost Train RMSE:", avg_xgb_rmse_train))
print(paste("XGBoost Test RMSE:", avg_xgb_rmse_test))
print(paste("SVM Train RMSE:", avg_svm_rmse_train))
print(paste("SVM Test RMSE:", avg_svm_rmse_test))
print(paste("GBM Train RMSE:", avg_gbm_rmse_train))
print(paste("GBM Test RMSE:", avg_gbm_rmse_test))
# Bayesian Model
df_model <- read_excel("reshaped_poi_locations.xlsx")
install.packages("torch")
library(torch)
# Define the Bayesian neural network model
BayesianModel <- nn_module(
"BayesianModel",
initialize = function() {
self.fc1 <- nn_linear(784, 512)
self.fc2 <- nn_linear(512, 256)
self.fc3 <- nn_linear(256, 10)
self.dropout <- nn_dropout(0.5)
self.log_var <- nn_parameter(1, requires_grad=TRUE)
},
forward = function(x) {
x <- self.fc1(x)
x <- F$relu(x)
x <- self.dropout(x)
x <- self.fc2(x)
x <- F$relu(x)
x <- self.dropout(x)
x <- self.fc3(x)
x <- F$log_softmax(x, dim = 1)
return(x)
},
kl_divergence = function() {
return(0.5 * torch_sum(torch_exp(self.log_var) + self.fc1$weight.pow(2) - self.log_var - 1))
}
)
# Define the training loop
train_bayesian_model <- function(model, train_loader, optimizer, num_epochs) {
model$train()
for (epoch in 1:num_epochs) {
for (batch in train_loader) {
inputs <- batch$images$reshape(-1, 784)  # Reshape the input tensor
targets <- batch$labels
optimizer$zero_grad()
outputs <- model(inputs)
loss <- F$nll_loss(outputs, targets) + model$kl_divergence()
loss$backward()
optimizer$step()
}
cat("Epoch:", epoch, "Loss:", loss$item(), "\n")
}
}
# Convert dataframe to tensors
df_model$Rating <- as.numeric(as.character(df_model$Rating))
df_tensor <- torch_tensor(as.matrix(df_model[, -"Rating"]), dtype = torch_double)
target_tensor <- torch_tensor(df_model$Rating, dtype = torch_long)
# Create a dataset and data loader
dataset <- torch_tensor_dataset(df_tensor, target_tensor)
data_loader <- torch_data_DataLoader(dataset, batch_size = 64, shuffle = TRUE)
# Create an instance of the Bayesian model
model <- BayesianModel()
# Define the optimizer
optimizer <- torch_optim_SGD(model$parameters(), lr = 0.001, momentum = 0.9)
# Train the Bayesian model
train_bayesian_model(model, data_loader, optimizer, num_epochs = 10)
# Define the optimizer
optimizer <- torch_optim_SGD(model$parameters(), lr = 0.001, momentum = 0.9)
# Bayesian Model
df_model <- read_excel("reshaped_poi_locations.xlsx")
library(torch)
# Define the Bayesian neural network model
BayesianModel <- nn_module(
"BayesianModel",
initialize = function() {
self.fc1 <- nn_linear(784, 512)
self.fc2 <- nn_linear(512, 256)
self.fc3 <- nn_linear(256, 10)
self.dropout <- nn_dropout(0.5)
self.log_var <- nn_parameter(1, requires_grad=TRUE)
},
forward = function(x) {
x <- self.fc1(x)
x <- F$relu(x)
x <- self.dropout(x)
x <- self.fc2(x)
x <- F$relu(x)
x <- self.dropout(x)
x <- self.fc3(x)
x <- F$log_softmax(x, dim = 1)
return(x)
},
kl_divergence = function() {
return(0.5 * torch_sum(torch_exp(self.log_var) + self.fc1$weight.pow(2) - self.log_var - 1))
}
)
# Define the training loop
train_bayesian_model <- function(model, train_loader, optimizer, num_epochs) {
model$train()
for (epoch in 1:num_epochs) {
for (batch in train_loader) {
inputs <- batch$images$reshape(-1, 784)  # Reshape the input tensor
targets <- batch$labels
optimizer$zero_grad()
outputs <- model(inputs)
loss <- F$nll_loss(outputs, targets) + model$kl_divergence()
loss$backward()
optimizer$step()
}
cat("Epoch:", epoch, "Loss:", loss$item(), "\n")
}
}
# Convert dataframe to tensors
df_model$Rating <- as.numeric(as.character(df_model$Rating))
df_tensor <- torch_tensor(as.matrix(df_model[, -"Rating"]), dtype = torch_double)
View(train_bayesian_model)
# Create a dataset and data loader
dataset <- torch_tensor_dataset(df_tensor, target_tensor)
data_loader <- torch_data_DataLoader(dataset, batch_size = 64, shuffle = TRUE)
# Create an instance of the Bayesian model
model <- BayesianModel()
# Define the optimizer
optimizer <- torch_optim_SGD(model$parameters(), lr = 0.001, momentum = 0.9)
# Train the Bayesian model
train_bayesian_model(model, data_loader, optimizer, num_epochs = 10)
# Set the model to evaluation mode
model$eval()
# Convert evaluation data to tensors
eval_inputs <- torch_tensor(as.matrix(df_eval[, -"Rating"]), dtype = torch_double)
eval_targets <- torch_tensor(df_eval$Rating, dtype = torch_long)
# Make predictions on evaluation data
with(torch_no_grad(), {
eval_outputs <- model(eval_inputs)
_, eval_predictions <- torch_max(eval_outputs, dim = 1)
# Calculate accuracy
eval_accuracy <- sum(eval_predictions == eval_targets) / length(eval_predictions)
cat("Accuracy:", eval_accuracy, "\n")
# Train the Bayesian model
train_bayesian_model(model, data_loader, optimizer, num_epochs = 10)
# Set the model to evaluation mode
model$eval()
# Convert evaluation data to tensors
eval_inputs <- torch_tensor(as.matrix(df_eval[, -"Rating"]), dtype = torch_double)
eval_targets <- torch_tensor(df_eval$Rating, dtype = torch_long)
# Make predictions on evaluation data
with(torch_no_grad(), {
eval_outputs <- model(eval_inputs)
_, eval_predictions <- torch_max(eval_outputs, dim = 1)
# Calculate accuracy
eval_accuracy <- sum(eval_predictions == eval_targets) / length(eval_predictions)
cat("Accuracy:", eval_accuracy, "\n")
# Set the model to evaluation mode
model$eval()
# Bayesian Model
df_model <- read_excel("reshaped_poi_locations.xlsx")
library(torch)
# Define the Bayesian neural network model
BayesianModel <- nn_module(
"BayesianModel",
initialize = function() {
self.fc1 <- nn_linear(784, 512)
self.fc2 <- nn_linear(512, 256)
self.fc3 <- nn_linear(256, 10)
self.dropout <- nn_dropout(0.5)
self.log_var <- nn_parameter(1, requires_grad=TRUE)
},
forward = function(x) {
x <- self.fc1(x)
x <- F$relu(x)
x <- self.dropout(x)
x <- self.fc2(x)
x <- F$relu(x)
x <- self.dropout(x)
x <- self.fc3(x)
x <- F$log_softmax(x, dim = 1)
return(x)
},
kl_divergence = function() {
return(0.5 * torch_sum(torch_exp(self.log_var) + self.fc1$weight.pow(2) - self.log_var - 1))
}
)
# Define the training loop
train_bayesian_model <- function(model, train_loader, optimizer, num_epochs) {
model$train()
for (epoch in 1:num_epochs) {
for (batch in train_loader) {
inputs <- batch$images$reshape(-1, 784)  # Reshape the input tensor
targets <- batch$labels
optimizer$zero_grad()
outputs <- model(inputs)
loss <- F$nll_loss(outputs, targets) + model$kl_divergence()
loss$backward()
optimizer$step()
}
cat("Epoch:", epoch, "Loss:", loss$item(), "\n")
}
}
# Convert dataframe to tensors
df_model$Rating <- as.numeric(as.character(df_model$Rating))
df_tensor <- torch_tensor(as.matrix(df_model[, -"Rating"]), dtype = torch_double)
# Bayesian Model
df_model <- read_excel("reshaped_poi_locations.xlsx")
# Define the number of bootstrap samples
n_boot <- 1000
# Create an empty vector to store the RMSE values
rmse_values <- numeric(n_boot)
# Perform bootstrapping
for (i in 1:n_boot) {
# Resample the test data with replacement
resampled_data <- test_data[sample(nrow(test_data), replace = TRUE), ]
# Make predictions on the resampled data
resampled_predictions <- predict(rf_model, data = resampled_data)$predictionsRs
# Calculate the RMSE on the resampled predictions
resampled_rmse <- sqrt(mean((resampled_predictions - resampled_data$Rating)^2))
# Store the RMSE value
rmse_values[i] <- resampled_rmse
}
# Compute the lower and upper bounds of the 95% confidence interval
lower_bound <- quantile(rmse_values, 0.025)
upper_bound <- quantile(rmse_values, 0.975)
# Print the confidence interval
cat("95% Confidence Interval for RMSE:", lower_bound, "-", upper_bound)
cor(predictions,actual_values)
# Load required library for plotting
library(ggplot2)
# Create a data frame with predictions and actual_values
data <- data.frame(predictions, actual_values)
# Plot the correlation using a scatter plot
ggplot(data, aes(x = predictions, y = actual_values)) +
geom_point() +
labs(x = "Predictions", y = "Actual Values") +
ggtitle("Correlation between Predictions and Actual Values") +
xlim(0, 5)
library(Rserve)
Rserve(args="--save")
library(randomForest)
library(caret)
library(xgboost)
library(rstanarm)
library(nnet)
library(readxl)
library(e1071)
library(gbm)
df_model <- read_excel("reshaped_poi_locations.xlsx")
# Set up 10-fold cross-validation
num_folds <- 10
folds <- createFolds(df_model$Rating, k = num_folds, list = TRUE, returnTrain = TRUE)
# Initialize vectors to store RMSE values for each model
rf_rmse_train <- numeric(num_folds)
rf_rmse_test <- numeric(num_folds)
xgb_rmse_train <- numeric(num_folds)
xgb_rmse_test <- numeric(num_folds)
svm_rmse_train <- numeric(num_folds)
svm_rmse_test <- numeric(num_folds)
gbm_rmse_train <- numeric(num_folds)
gbm_rmse_test <- numeric(num_folds)
# Perform cross-validation
for (i in 1:num_folds) {
# Get training and testing data for the current fold
train_data <- df_model[folds[[i]], ]
test_data <- df_model[-folds[[i]], ]
# Random Forest
rf_model <- randomForest(formula = Rating ~ ., data = train_data)
rf_pred_train <- predict(rf_model, newdata = train_data)
rf_rmse_train[i] <- sqrt(mean((rf_pred_train - train_data$Rating)^2))
rf_pred_test <- predict(rf_model, newdata = test_data)
rf_rmse_test[i] <- sqrt(mean((rf_pred_test - test_data$Rating)^2))
# Assuming "Rating" is the column name you want to find the number of
column_name <- "Rating"
column_number <- which(names(df_model) == column_name)
# XGBoost
xgb_model <- xgboost(data = as.matrix(train_data[, -column_number]), label = train_data$Rating, nrounds = 100)
xgb_pred_train <- predict(xgb_model, newdata = as.matrix(train_data[, -column_number]))
xgb_rmse_train[i] <- sqrt(mean((xgb_pred_train - train_data$Rating)^2))
xgb_pred_test <- predict(xgb_model, newdata = as.matrix(test_data[, -column_number]))
xgb_rmse_test[i] <- sqrt(mean((xgb_pred_test - test_data$Rating)^2))
# SVM
svm_model <- svm(Rating ~ ., data = train_data, kernel = "radial")
svm_pred_train <- predict(svm_model, newdata = train_data)
svm_rmse_train[i] <- sqrt(mean((svm_pred_train - train_data$Rating)^2))
svm_pred_test <- predict(svm_model, newdata = test_data)
svm_rmse_test[i] <- sqrt(mean((svm_pred_test - test_data$Rating)^2))
# GBM
gbm_model <- gbm(Rating ~ ., data = train_data, n.trees = 100, interaction.depth = 3, shrinkage = 0.1)
gbm_pred_train <- predict(gbm_model, newdata = train_data, n.trees = 100)
gbm_rmse_train[i] <- sqrt(mean((gbm_pred_train - train_data$Rating)^2))
gbm_pred_test <- predict(gbm_model, newdata = test_data, n.trees = 100)
gbm_rmse_test[i] <- sqrt(mean((gbm_pred_test - test_data$Rating)^2))
}
# Compute the average RMSE across all folds
avg_rf_rmse_train <- mean(rf_rmse_train)
avg_rf_rmse_test <- mean(rf_rmse_test)
avg_xgb_rmse_train <- mean(xgb_rmse_train)
avg_xgb_rmse_test <- mean(xgb_rmse_test)
avg_svm_rmse_train <- mean(svm_rmse_train)
avg_svm_rmse_test <- mean(svm_rmse_test)
avg_gbm_rmse_train <- mean(gbm_rmse_train)
avg_gbm_rmse_test <- mean(gbm_rmse_test)
# Print average RMSE for each model
print(paste("Random Forest Train RMSE:", avg_rf_rmse_train))
print(paste("Random Forest Test RMSE:", avg_rf_rmse_test))
print(paste("XGBoost Train RMSE:", avg_xgb_rmse_train))
print(paste("XGBoost Test RMSE:", avg_xgb_rmse_test))
print(paste("SVM Train RMSE:", avg_svm_rmse_train))
print(paste("SVM Test RMSE:", avg_svm_rmse_test))
print(paste("GBM Train RMSE:", avg_gbm_rmse_train))
print(paste("GBM Test RMSE:", avg_gbm_rmse_test))
